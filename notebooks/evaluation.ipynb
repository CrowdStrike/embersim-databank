{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "787ef0f9-5fe7-4b61-b09e-60d172636aff",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dfbcfc5-5e92-4cff-989e-6333a016901e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import ast\n",
    "import json\n",
    "import pickle\n",
    "import re\n",
    "import sys\n",
    "from collections import Counter, defaultdict\n",
    "from functools import reduce\n",
    "from operator import itemgetter\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "import seaborn as sns\n",
    "import toolz\n",
    "from rich import print\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "tqdm.pandas()\n",
    "sns.set()\n",
    "\n",
    "sys.path.insert(0, \"../src\")\n",
    "\n",
    "from dataset import (\n",
    "    TagAssociations,\n",
    "    TagAugmenter,\n",
    "    get_most_prevalent_tag,\n",
    "    get_tag_ranking,\n",
    "    normalise_wrt,\n",
    ")\n",
    "from evaluation import RelevanceAtK, RelevanceMethods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a09110d-9b78-4df6-9030-0b4391d2694b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fe77d90f-c37b-4b92-a923-6244a60a2813",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe8298d-b735-47cc-9b06-6a6f5020077e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = pd.read_pickle(\n",
    "    \"../data/processed/ember_with_avclass_dataset.pkl\"\n",
    ")  # .set_index('sha256')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95755bde-b972-4090-bb88-79823faa3186",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sim_unl_vs_train = pd.read_pickle(\n",
    "    \"../data/processed/xgb-sim-results/unlabelled_vs_train.pkl\"\n",
    ").set_index(\"needle_sha256\")\n",
    "sim_test_vs_traintest = pd.read_pickle(\n",
    "    \"../data/processed/xgb-sim-results/test_vs_train_test.pkl\"\n",
    ").set_index(\"needle_sha256\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ba3648-90b4-4ffd-9752-d1d175096cd4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "unl_clean = set(\n",
    "    dataset.query(\"label == -1 & avclass_prev.isna() & avclass_curr.isna()\")[\"sha256\"]\n",
    ")\n",
    "unl_dirty = set(\n",
    "    dataset.query(\"label == -1 & (avclass_prev.notna() | avclass_curr.notna())\")[\n",
    "        \"sha256\"\n",
    "    ]\n",
    ")\n",
    "assert 200_000 == len(unl_clean) + len(unl_dirty)\n",
    "\n",
    "test_clean = set(dataset.query('label == 0 & subset == \"test\"')[\"sha256\"])\n",
    "test_dirty = set(dataset.query('label == 1 & subset == \"test\"')[\"sha256\"])\n",
    "assert 200_000 == len(test_clean) + len(test_dirty)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e6ebe41a-ed46-4d9e-b222-02769ca957ec",
   "metadata": {},
   "source": [
    "## Eval"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d756e56a-e2ec-4c33-978c-ace9166280dc",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Label homogeneity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be47b867-aa34-408b-a903-42b4e8648483",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sim = sim_test_vs_traintest\n",
    "clean, dirty = test_clean, test_dirty\n",
    "\n",
    "clean_subset = sim.loc[list(clean)]\n",
    "dirty_subset = sim.loc[list(dirty)]\n",
    "ds = dataset.set_index(\"sha256\")\n",
    "\n",
    "\n",
    "def agg(hs):\n",
    "    ys = {}\n",
    "    for K in [1, 10, 50, 100]:\n",
    "        ys[f\"top-{K}\"] = ds.loc[hs[:K], \"label\"].value_counts().to_dict()\n",
    "    return ys\n",
    "\n",
    "\n",
    "out = sim[\"hits_sha256\"].progress_apply(agg).apply(pd.Series)\n",
    "out[\"true\"] = out.index.map(lambda h: int(h in dirty))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a443b7-a666-4e00-a924-8f6f9965b5e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lh_file = \"../data/processed/eval-results/label_homogeneity_test_vs_traintest.pkl\"\n",
    "# out.to_pickle(lh_file)\n",
    "out = pd.read_pickle(lh_file)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0ed5c7ed-2d48-42c8-9d62-5761921fbea2",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6931751-83a8-4300-ab7f-ca0f91faad5e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "_, axs = plt.subplots(figsize=(14, 4), nrows=1, ncols=3)\n",
    "\n",
    "meta = {\n",
    "    0: {\"color\": \"skyblue\", \"label\": \"benign\", \"alpha\": 0.5},\n",
    "    1: {\"color\": \"salmon\", \"label\": \"malicious\", \"alpha\": 1},\n",
    "}\n",
    "bins = np.linspace(0, 1, endpoint=True, num=21)\n",
    "\n",
    "for i, k in enumerate([10, 50, 100]):\n",
    "    ax = axs[i]\n",
    "    for l in [1, 0]:\n",
    "        xs = (\n",
    "            out.query(f\"true == {l}\")[f\"top-{k}\"]\n",
    "            .apply(lambda d: d.get(l, 0) / k)\n",
    "            .to_list()\n",
    "        )\n",
    "        sns.histplot(xs, stat=\"percent\", bins=bins, ax=ax, **meta[l])\n",
    "        ax.set_xticks(bins[::2])\n",
    "        ax.set_yscale(\"log\")\n",
    "        iy = [0.1, 1, 5, 10, 50, 90]\n",
    "        ax.set_yticks(iy, labels=[f\"{i}%\" for i in iy])\n",
    "        ax.set_title(f\"Top {k} hits\")\n",
    "        ax.legend()\n",
    "        # ax.set_xlabel(f\"Fraction of hits matching labels with query\")\n",
    "\n",
    "plt.suptitle(f\"Fraction of hits matching labels with query\")\n",
    "plt.tight_layout()\n",
    "pass"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d4397ae0-7931-431e-af79-3eed69839f58",
   "metadata": {},
   "source": [
    "#### ECDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fc3823d-f048-48bd-8534-bd71aed0df03",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "_, axs = plt.subplots(figsize=(12, 4), nrows=1, ncols=3)\n",
    "\n",
    "meta = {\n",
    "    0: {\"c\": \"skyblue\", \"label\": \"benign\"},\n",
    "    1: {\"c\": \"salmon\", \"label\": \"malicious\"},\n",
    "}\n",
    "\n",
    "for i, k in enumerate([10, 50, 100]):\n",
    "    ax = axs[i]\n",
    "    for l in [0, 1]:\n",
    "        xs = sorted(\n",
    "            out.query(f\"true == {l}\")[f\"top-{k}\"]\n",
    "            .apply(lambda d: d.get(l, 0) / k)\n",
    "            .to_list()\n",
    "        )\n",
    "        ix = np.linspace(0, 1, endpoint=True, num=len(xs))\n",
    "        ax.plot(xs, ix, **meta[l])\n",
    "        ax.set_yscale(\"log\")\n",
    "        tk = np.linspace(0, 1, num=11)\n",
    "        ax.set_xticks(tk)\n",
    "        ax.set_xticklabels([f\"{i:.1f}\" for i in tk])\n",
    "        ax.set_xlabel(f\"Fraction of hits\")\n",
    "        ax.set_ylabel(f\"Fraction of all samples\")\n",
    "        ax.set_title(f\"Top {k} hits\")\n",
    "        # ax.grid(True, which='both')\n",
    "        ax.legend()\n",
    "\n",
    "plt.suptitle(f\"Fraction of hits matching labels with query\")\n",
    "plt.tight_layout()\n",
    "pass"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "302d138c-7c55-415c-a170-f3f14f2fb10e",
   "metadata": {},
   "source": [
    "### Relevance@K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c0b9a5-a588-4439-a338-4d178f8376f4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def relevance_at_k(res):\n",
    "    return pd.Series(\n",
    "        {f\"top-{K}\": np.mean([r[2] for r in res[:K]]) for K in [1, 10, 50, 100]}\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2d07383f-a2ad-408e-a9bd-97814690c3dd",
   "metadata": {},
   "source": [
    "#### Table summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c1990a-2700-40c1-8dc3-ca2d29ac9889",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def summarize(df, qs):\n",
    "    def summarize_single(xs, qs):\n",
    "        qs = np.array(qs) * 100\n",
    "        ps = np.round(np.percentile(xs, qs), 3)\n",
    "        return {\n",
    "            \"mean\": np.mean(xs),\n",
    "            \"std\": np.std(xs),\n",
    "            \"percentiles\": dict(zip(qs, ps)),\n",
    "            \"skew\": stats.skew(xs),\n",
    "            \"kurtosis\": stats.kurtosis(xs),\n",
    "        }\n",
    "\n",
    "    # ---\n",
    "\n",
    "    out = {}\n",
    "\n",
    "    for k in [1, 10, 50, 100]:\n",
    "        t = f\"top-{k}\"\n",
    "        out[t] = summarize_single(df[t].to_numpy(), qs)\n",
    "\n",
    "    return pd.DataFrame(out).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ae822d-345c-441a-9f36-343f6253e430",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "datasets = {\n",
    "    \"unl_vs_train\": {\n",
    "        \"clean\": unl_clean,\n",
    "        \"dirty\": unl_dirty,\n",
    "    },\n",
    "    \"test_vs_traintest\": {\n",
    "        \"clean\": test_clean,\n",
    "        \"dirty\": test_dirty,\n",
    "    },\n",
    "}\n",
    "\n",
    "qs = np.array([0.01, *np.linspace(0, 1, endpoint=True, num=21)[1:]])  # percentiles\n",
    "out = []\n",
    "\n",
    "for kind in [\"class\", \"fam\"]:\n",
    "    for dataset, labels in datasets.items():\n",
    "        for file in sorted(\n",
    "            Path(f\"../data/processed/eval-results-fix/{kind}-ranking\").glob(\n",
    "                f\"{dataset}*.pkl\"\n",
    "            )\n",
    "        ):\n",
    "            # read file\n",
    "            df = pd.read_pickle(file)\n",
    "            df = pd.concat([df, df[\"results\"].progress_apply(relevance_at_k)], axis=1)\n",
    "\n",
    "            # extract info from file name\n",
    "            m = re.match(\n",
    "                f\"{dataset}_top_100_rank_(?P<rank_by>\\w+)_occur_(?P<thr>0\\.\\d+)_rel_(?P<rel>\\w+).pkl\",\n",
    "                file.name,\n",
    "            )\n",
    "            assert m is not None\n",
    "            attr = m.groupdict()\n",
    "            assert attr[\"rank_by\"].lower() == kind\n",
    "\n",
    "            # summarise results for both clean/dirty\n",
    "            for l, subset in enumerate(\n",
    "                (labels[\"clean\"], labels[\"dirty\"], labels[\"clean\"] | labels[\"dirty\"])\n",
    "            ):\n",
    "                tmp_df = df.query(\"sha256.isin(@subset)\")\n",
    "                out.append(\n",
    "                    summarize(tmp_df, qs)\n",
    "                    .reset_index(names=\"Top-K\")\n",
    "                    .assign(\n",
    "                        **{\n",
    "                            \"dataset\": dataset,\n",
    "                            \"co_occur_thr\": float(attr[\"thr\"]),\n",
    "                            \"rank\": attr[\"rank_by\"],\n",
    "                            \"relevance_func\": attr[\"rel\"],\n",
    "                            \"label\": \"both\" if l == 2 else l,\n",
    "                            \"subset_size\": len(tmp_df),\n",
    "                        }\n",
    "                    )\n",
    "                )\n",
    "\n",
    "out = pd.concat(out, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88746027-060a-461b-82f1-6b5e778cd7b6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# out.to_csv(\"../data/processed/eval-results-fix/paper_results_all_split.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a73a0d94-f3c1-48a4-8b69-54c637c31c20",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "out = pd.read_csv(\"../data/processed/eval-results-fix/paper_results_all_split.csv\")\n",
    "\n",
    "ps = [1, 10, 50, 95]\n",
    "out[\"percentiles\"] = (\n",
    "    out[\"percentiles\"].apply(ast.literal_eval).apply(lambda d: [d[p] for p in ps])\n",
    ")\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24dd85d7-f1db-4233-8325-e09870269c29",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "DATASET = \"unl_vs_train\"\n",
    "print(\"%\", DATASET)\n",
    "\n",
    "_base = ['(rank == \"FAM\")', \"(co_occur_thr == 0.9)\", '(top_k != \"top-50\")']\n",
    "_extra = [f'(dataset == \"{DATASET}\")', ('label != \"both\"')]\n",
    "cols = [\"relevance_func\", \"top_k\", \"mean\", \"std\", \"percentiles\", \"label\"]\n",
    "\n",
    "cur = out.query(\"&\".join(_base + _extra))[cols].reset_index(drop=True)\n",
    "cur[\"mean (std)\"] = cur.apply(\n",
    "    lambda row: f'{row[\"mean\"]:.3f} ({row[\"std\"]:.3f})', axis=1\n",
    ")\n",
    "cur[\"skew\"] = cur[\"skew\"].round(3)\n",
    "cur = (\n",
    "    cur.drop([\"mean\", \"std\"], axis=1)\n",
    "    # .set_index(['relevance_func', 'top_k'])\n",
    ")\n",
    "\n",
    "c0 = cur.query('label == \"0\"').drop(\"label\", axis=1)[[\"mean (std)\", \"percentiles\"]]\n",
    "c1 = cur.query('label == \"1\"').drop(\"label\", axis=1)[[\"mean (std)\", \"percentiles\"]]\n",
    "cur = pd.concat([c0, c1], axis=1)\n",
    "\n",
    "# cur.query('label == \"1\"')\n",
    "# print(cur.to_latex().replace('top-', '').replace('[', '').replace(']', ''))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "84870a79-fe40-478a-aa98-85eb4b8814d5",
   "metadata": {},
   "source": [
    "#### Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39431b4c-83a8-473c-af90-eb7c075572d0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_results(xs: list[float], ax1):\n",
    "    xs = sorted(xs)\n",
    "    ys = np.linspace(0, 1, num=len(xs))\n",
    "\n",
    "    ax1.plot(xs, ys, lw=2, color=\"skyblue\")\n",
    "    ax1.set_ylabel(\"ECDF\")\n",
    "\n",
    "    ax2 = ax1.twinx()\n",
    "    sns.histplot(xs, stat=\"percent\", bins=32, alpha=0.9, ax=ax2, color=\"salmon\")\n",
    "    ax2.set_ylabel(\"Percent\")\n",
    "\n",
    "\n",
    "def ecdf(data):\n",
    "    xs = sorted(data)\n",
    "    ix = np.linspace(0, 1, num=len(data))\n",
    "    return {\"x\": xs[::100], \"y\": ix[::100]}\n",
    "\n",
    "\n",
    "def show_exp(df, clean_hashes, dirty_hashes, K, ax):\n",
    "    df[\"relevance\"] = df[\"results\"].apply(lambda res: np.mean([r[2] for r in res[:K]]))\n",
    "    clean = df.query(\"sha256.isin(@clean_hashes)\")[\"relevance\"]\n",
    "    dirty = df.query(\"sha256.isin(@dirty_hashes)\")[\"relevance\"]\n",
    "    print(f\"{len(clean)=:,d} | {len(dirty)=:,d}\")\n",
    "\n",
    "    bins = np.linspace(0, 1, 21)\n",
    "    stat = \"percent\"\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(12, 6), nrows=2, ncols=2, sharex=False)\n",
    "    ax[1, 1].remove()\n",
    "    ax[1, 0].invert_yaxis()\n",
    "\n",
    "    ax[0, 0].set_xlabel(f\"Precision@{K}\")\n",
    "    ax[1, 0].set_xlabel(f\"Precision@{K}\")\n",
    "    sns.histplot(\n",
    "        clean, ax=ax[0, 0], bins=bins, stat=stat, color=\"skyblue\", label=\"~clean\"\n",
    "    )\n",
    "    sns.histplot(\n",
    "        dirty, ax=ax[1, 0], bins=bins, stat=stat, color=\"salmon\", label=\"~dirty\"\n",
    "    )\n",
    "\n",
    "    ax[0, 0].legend()\n",
    "    ax[1, 0].legend()\n",
    "    plt.subplots_adjust(hspace=0)\n",
    "    ax[1, 0].set_xticks(bins[::2])\n",
    "    ax[0, 0].set_title(\"Histogram of precision\")\n",
    "\n",
    "    sns.lineplot(**ecdf(clean), ax=ax[0, 1], lw=2, color=\"skyblue\", label=\"~clean\")\n",
    "    sns.lineplot(**ecdf(dirty), ax=ax[0, 1], lw=2, color=\"salmon\", label=\"~dirty\")\n",
    "    ax[0, 1].set_xticks(bins[::2])\n",
    "    ax[0, 1].set_xlabel(f\"Precision@{K}\")\n",
    "    ax[0, 1].set_ylabel(\"Fraction of samples\")\n",
    "    ax[0, 1].set_title(\"Empirical CDF\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
